<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Alex Carvalho">
    <meta name="description" content="This blog covers Metadata and my understanding on how/why it is used">
    <script  src= "../back-to-archive.js" type="module" async></script>
    <link rel="stylesheet" href="../../../css/main.css">
    <title>Development Blog:02/03/2020</title>
</head>
<body>
    <header><br><button class="back_to_blog_archive">Back to Archive</button></header>
    <br>
<article class="h-entry">
    <h2 class="p-name">Metadata and the Bookworms that Crawl on the Web Reading it</h2>
    <p class="p-author">Posted by Alex Carvalho on <time class="dt-published" datetime="02/03/2020">the 2<sup>nd</sup> March 2020</time></p>
    <p>
        This week we covered the <a href="https://opensourceforu.com/2017/07/ web-robots-worker-bees-internet/"target="_blank" rel="noopener">web robots</a> and their function on the internet. <br><br>
        As I understand it these robots scour the internet gathering information, this information is used both for good (legitimate) 
        and evil (malicious).
        <br><br>
        The good robo bros are used to organize/index information on the web so that it can easily be found and catalogue, finds price
        variations of the same thing from multiple sources. This allows people to make more informed decisions when buying online. They 
        are also used to provide a constant source of media to people. Basically, all the good robo bros make navigating the web easier
        for people, and makes traversing the web so much faster.
        <br><br>
        The evil robos operate the same as the good robos, however what information they gather or what the information is used for is 
        different. <i>Spam bots</i> collect information, typically contact info like email addresses, about users to spam them with advertising.
        <i>Hacker web robots</i> try and find vulnerable websites or application so they can be exploited for malicious purposes (side note:
        shouldn't these robots be called "Cracker web robots" instead then?). <cire>Botnets</cire> are a network of 'zombie computers' that are used
        to conduct coordinated online attacks. <i>Download web robots</i>  forcible downloads a specific web page instead of the requested page.
        <br><br>
        The metadata of a websites is what these robots reads. Each site has its own metadata that is not displayed to the user but rather
        is displayed for the robots scanning through the web. The metadata is used to describe what is the webpage about or what is 
        the important aspects of the site that wants to be shared. This can be who the author is, what is on the website, the keywords
        associated with products, etc. The main goal being to make the website as accessible as it needs to be. The metadata specifies
        who, what and how many people will be able to find the website if it is what they are looking for.   
    </p>

    <article class="h-entry">
        <h2 class="p-name">Metadata Revisited</h2>
        <p class="p-author">Posted by Alex Carvalho on <time class="dt-published" datetime="17/04/2020">the 17<sup>th</sup> April 2020</time></p>
        <p>
            
        </p>
    
    </article>
</article>
    
</body>
</html>