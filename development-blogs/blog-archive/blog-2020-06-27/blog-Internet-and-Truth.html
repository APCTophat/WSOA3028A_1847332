<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Alex Carvalho">
    <meta name="description" content="A blog post about two science communicator videos">
    <script  src= "../back-to-archive.js" type="module" async></script>
    <link rel="stylesheet" href="../../../css/main.css">
    <link rel="stylesheet" href="../../../css/content.css">
    <title>Development Blog:27/06/2020</title>
</head>
<body>
    <header>
<section> 
    <a class="back_to_blog_archive">Back to Archive</a>
    </section>
</header>
<article class="The_Post">
<article class="The_Post_Container">
    <h2 class="p-name">The Internet and Truth</h2>
    
    
    <div class="Post_Text">
        <p class="p-author">Posted by Alex Carvalho on <time class="dt-published" datetime="27/06/2020">the 27<sup>th</sup> June 2020</time></p>
        <p>
            This blog is centred around two YouTube videos I want to discuss. As YouTube is my primary source of information gathering. I found these two videos discussing the internet and what that means for our perception of what is “truth”. I want to discuss what was brought up and add to the discussion. I will be discussing both videos separately before tying it all together in a reflection section. While the people in these videos are not the most qualified people to talk about these topics. I perceive their incite into these topics to be credible and useful as they have built a reputation of being well researched and a source of trustworthy information. Obviously, this is my perception of their work and I could just be finding communities on the internet that reaffirm my own opinion on this topic (something they both bring up). I want to clearly state their stance on the topic they talk about and then comment what my opinion on the subject is.
            </p>
            <h2>Post-Truth: Why facts Don’t Matter Anymore</h2>
            <p>
            The first video I want to talk about comes from the channel <a href="https://www.youtube.com/watch?v=dvk2PQNcg8w" target="blank"><cite>Veritasium</cite></a> presented by Derek Muller. Derek has established himself as a science communicator, building his channel to talk about and engage with the sciences. He has a PhD in physics education research, but I personally do not watch him for his qualifications. I watch his content because he is a person I trust. If he says up is up and down is down, I tend to believe him. The idea of “the person presenting the content is what draws people interests and not the content itself” is brought up in the second video but I will talk more about when I discuss that video.
            </p>
            <p>
            Firstly, in this video Derek is addressing a classroom of students and speaks to include them in the discussion. So, while addressing the physical audience he also addresses the digital audience watching the video. I believe this is deliberately done to present this topic as a discussion piece as well as make the digital audience to feel more present in the discussion. 
            </p>
            <p>
            Derek discusses the idea that he thought the internet would have brought people together where it seems like it has just divided the internet further. He asks why things is there still such a “miss information” and “fake news” when every person can open their phone and immediately fact check anything anyone is saying. He brings up the argument that the internet is a place of communities (maybe a more apt term would be factions). That a person can find like minded people far easier on the internet than it can in the person. This is both a good and a bad thing, while this interconnected system facilitates the coming together of people who want to make good and share progressive arguments, it also facilitates the gathering of people who express bigotry and hate towards any person “they” deem incorrect. He also explains that while a typical group might make up a small percentage of a typical population, on the internet all these small groups can find each other and make a much large community (again a good and bad thing).
            </p>
            <p>
            Derek also talks about the discourse that occurs within these communities. About how a piece of information bounces from person to person. Each time changing ever so slightly and the most “button pushy” changes are the ones that stick as they encourage propagation. If something is too plain or too extreme, it will not be continued to be spread throughout the community. Eventually what the main discussion is leaves the community that formed it and enters the spheres of other communities. That is why we have great masterpieces like “I can has cheezburger?” floating around the internet and it not limited to just a cat loving internet community. 
            </p>
            <p>
            He describes it as a self-feeding cycle. There is the <i>Engaging thing</i> then <i> people love/hate it</i> then they <i>promote it</i>. This leaves communities not arguing with the other community but arguing with what they think the other community’s argument is. It is the algorithms that facilitate this, as most algorithms promote engagement. The way people engage divides people into factions pushing them apart. Polarising any discussion and not leaving the middle grey area as a platform with a large voice. This polarising facilitated by this cyclical nature of discussion remediation. Once that one thing about an argument is the most “button pushy” it pushes all other forms of the argument out of the discourse.
            </p> 
            <h3>My thoughts</h3>
            <p>
            Unsurprisingly I tend to agree with what Derek Muller is saying about his perception of his of the internet. I agree with the idea that the internet forms communities of like-minded people and when there is clash between these communities, they argue based off their own perception of what the argument is. I do not know enough about how algorithms are coded and function to comment of his perception that algorithms promote this kind of behaviour. However my experiences with these engagement systems on social media platforms would leave me to believe that what he is saying has some truth. With regards to how the <i>thing</i> being engaged with the most, floats to the top and gets propagated more.
            </p>    
            <h2>There is no Algorithm for truth</h2>

<p>
This video was posted by  <a href="https://www.youtube.com/watch?v=leX541Dr2rU" target="blank"><cite>The Royal Institution</cite></a> and it is presented by Tom Scott. Tom has created his own YouTube following and another education entertainer. With his videos being about history, science, technology, and linguistics. Like Derek while he may not be the most qualified person in these topics, he has built a reputation of being well researched and a trustworthy source about these topics. He does have a degree in linguistics but like Derek it is more about the “person” providing the information rather than their qualifications that make them trustworthy. A point he brings up in this video. 
</p>
<p> 
In this video he is investigating the “State of science communication, in the English-speaking world at the end of the second decade of the 21<sup>st</sup> century. He has split his talk into five parts, and I will break down the major points he brings up in each. Like Derek he is addressing an audience at the Royal Institute. He makes a point that the only reason he is giving this presentation is because he has worked with them before and that he is a recognisable name that may drive ticket sales. By just his association with this presentation drives interest in the talk. Which is a big part of science communication today but is not something new.
</p>
<p>
<h4>Part 1: The Algorithm</h4>
<p>
In this first part Tom talks about “Algorithms” that magical black box of code that does things that people are not entirely sure how it does everything it does. He breaks down the basic idea that goes into forming an algorithm. It begins with the <i>set up</i>  (this is the programming) then the program is <i> provided human curated examples</i> and told to work out <i>distinguishing features and categorise them</i> it is them provided with <i>novel examples</i> to categorise, it then <i>learns from feedback</i>. He states that while this system may seem un-bias or neutral, the initial data presented to the system has a massive impact on what the system learns and categories it creates. He states that through bad/biased training data the algorithm becomes bias. Saying it is AI inheriting systemic biases. 
<p>
He continues by quoting <i> Goodhart’s Law</i> - “When a metric becomes a target, it ceases to be a good measure”.  Meaning that if an algorithm is created to meet a certain goal, the data it output that meets that goal are not a good measure of how well the algorithm is performing. As the creators may have created a biased algorithm that produces the desired outcome based off bad/biased metrics. 
</p>
<p>
He continues to give example of qualities of the YouTube algorithm that has influenced the contented that is seen, popular and propagated. He describes how the video recommending system promotes radicalisation, as the most radical type of videos gets the most views/are watched for a longer time/keeps the person on the site. He states that a typical example of a YouTube string of videos recommendations could be <i>Apolitical video</i>, <i>Slightly political video</i>, <i>Click bait video</i>, and <i>Radically video</i>. He states that the YouTube culture created by the algorithm, is about being “hardcore”. The viewer is never “hardcore” enough in the thing they are interested in. Example is if a person is watching videos about “jogging”, YouTube will begin to suggest “marathoning” to try and keep the viewer on the website. This is inherit radicalisation and is systemic across the platform according to Tom.
</p>
<p>
The final quote from Tom I want to highlight from this section is <i>“If you want to be convinced of a thing, YouTube/Twitter/ect is happy to find you people to convince you”</i>. 

<h4>The State of Science Communication</h4>
<p>
Tom highlights the decisions made by organizations on “Who, What, When, Where and Why” presents information they want to be presented are not based off one metric. They do not just pick the “best/most qualified” person for the job but also make a decision on recognizability, perceived trustworthiness and notoriety. As Tom says this is why the title is “Wonders of Life presented by Brian Cox” and not just “Wonders of Life”. Regardless that Brian Cox is a physicist presenting a nature documentary, his name will peek people’s interest. 
</p>
<p>
Tom equates the behaviour of how the internet functions is that of a band where their first song was a number one hit. Everything that band does will be compared to that one thing they are known for. People don’t want to see new, they want to see that number one hit again. If a person makes a name for themselves on the internet off one viral hit. The “audience” will only want to see that one thing over and over again until they get bored and then move on. The antithesis to this is building a community based off smaller, minor successes over time.  So the online creator is not weighed down by the “one thing” they are known for. The final part to this Tom says is “Its not about spectacle, its about people”. 

</p>
<h4>Parasocial relationships</h4>
<p>
Tom explains that there is a difference between the relationship a spectator and the performer has. They do not exist on the same level in the relationship, the performer has the power/influence while the spectator follows behind. This is a one-way relationship. When considering this relationship, the performer is essentially “Selling Friendship” as Tom puts it. Taking the example of a Twitch streamer. They ‘perform’ for their audience by doing something (typically playing a video game) but they also interact with their audience through a chat. Greeting familiar names when they speak to chat or welcome new people to their community through a donation notification that the rest of the audience sees. 
<p>
This parasocial relationships can get to the point where the audience is no longer a fan of the persons <i>work</i> but is a fan of that <i>person</i>. This is nothing new, movies and TV have used parasocial relationships of celebrities to ensure ticket sales since there were celebrities. For example, people said, “Did you see, Ryan Reynolds is playing pikachu in Detective Pikachu” and not “Hey did you see they are making a movie about the pokemon spin-off game Detective Pikachu”. This level of fandom for the person is a major factor in online culture. Tom brings up the example of Simon Clark, he was getting his PhD is atmospheric physics and uploading videos to YouTube about his studies. Simon said the he became the “commodity” and not his work. People wanted to watch the person getting his PhD and was not interested in the PhD itself. Eventually he stopped talking about himself during his work and focused ONLY on his work.
</p>
<h4>Echo Chambers and Nazi Bars</h4>
<p>
Both are bad things on opposite side of a spectrum that each platform that allows content to be produced on it needs to fall between. There is no right ‘place’ on this spectrum for a site to fall on and it nearly impossible to manage. A “nazi bar” is the problem when an online platform is <i>too open</i> with what content can be produced on their platform. While an “echo chamber” is the opposite, where the prevailing stance presented on the site is the only discussion point and no new positions can be explored.
<p>
To describe discourse on the internet Tom talks about the two concepts of the <i>Echo Chamber</i> and the <i>Nazi Bar</i>. To describe the nazi bar, “If there is a bar that is the best place in town but the nazi’s meet in the basement you wont go or your won’t tell your friends to go or that you go. The basic idea is that if there is a platform on the internet where “the nazis” can meet, it will drive out people who do not want to be associated with that platform or see that sort of content on that platform. This creates a repeating cycle where <i>the “nazis” join and create content</i>, <i>people leave</i>, <i>percentage of “nazi” content on the site increases</i> which would then make the site more appealing to “the nazis” and the entire cycle begins again. 
</p> 
<p>
The “echo chanmber” promotes people for agreeing with the prevailing stance taken on the stance. So if the stance is that A is right and B is wrong, all content that agrees is promoted and spread while any content that disagrees is drowned out and not discussed. This produces a climate where any bigotry or hate can brew and thrive.
</p>
<h4>There is no algorithm for truth</h4>
<p>
Finally, Tom concludes that there is no algorithm for truth, that it is up to people to change the way the internet works. It is up to the programmers to manage what they want their systems to do and what data they are feeding these systems for it to learn. It is up to each individual to recognise what is being said and see if what they are agreeing with is confirmation bias. The internet is a wonderful place made by wonderful people and a terrible place made by terrible people. Where the only algorithm for truth is ourselves.
</p>

<h4>Overall thoughts</h4>
<p>
It is clear that I am in agreement for the most part with these two videos or else why would I want to talk about them. It is likely the systemic belief that a white man with an authoritative tone is trustworthy, leads me to believe these two white men with an authoritative tone. I also am familiar with these two individuals prior to these videos so that can also contribute to my agreement. While the general idea that the internet facilitates the creation of smaller communities is something, I agreed with prior to viewing these videos. They did introduce me to some concepts that I had not considered before. The idea of how ideas bounce around in communities before the most “button pushy” one propagates outwards was a new perspective for me. After thinking about I found myself tending to agree with this idea knowing the discourse I experience within the communities I know. Then when something is super popular in that community eventually someone (typically my parents) ask me about this <i>thing</i> they heard about and know I would know of it. A thing that completely shocked me was the topic of the <i>parasocial relationships</i>, as I had never been exposed to this topic. I found this topic hauntingly true when I was considering my own life experiences. To sum up I generally agreed with the videos and I hoped that I agreed because they are “true” but it could be due to prior biases and prior systemic beliefs.
</p>

            
    </div>
</article>
</article>
</body>
</html>